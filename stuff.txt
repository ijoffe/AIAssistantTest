def objectdetection_model(video_stream, od_model):
    od_model.predict(
        source=video_stream,
        show=True,              # open window with live labels
        vid_stride=25,           # skip every other frame for speed
        verbose=False,          # don't print outputs
        device='cpu',           # large language model gets to use gpu
    )
    return




def main():
    video_input = "/dev/video1"  # Input device
    video_output = "/dev/video2"  # Output device
    # run preliminaries so application can be run
    od_model, ll_model, ll_processor = setup()
    # set up video as a separate thread
    objectdetection_t = threading.Thread(target=objectdetection_model, args=(video_input, od_model,))
    objectdetection_t.start()
    # run language modelling on the main thread for website communication
    largelanguage_model(video_input, ll_model, ll_processor)
    return

if __name__ == "__main__":
    main()

# sudo modprobe v4l2loopback devices=1 video_nr=1 card_label="VirtualCam"
#gst-launch-1.0 thetauvcsrc mode=4K ! h264parse ! avdec_h264 ! videoconvert ! v4l2sink device=/dev/video1
